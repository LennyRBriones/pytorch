{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU7w7DTHHvNM70QhrGjPKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LennyRBriones/pytorch/blob/main/creating_a_model_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch"
      ],
      "metadata": {
        "id": "w-y3mROW6H69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, nn.Module is very important. being the class that allows you create, store and manipulate all layers and operations in the neural networks.\n",
        "\n",
        "This is very important because with the nn.module you only need to keep focus in the model building and results, the layers will be attended by the nn.module for you\n",
        "\n"
      ],
      "metadata": {
        "id": "dLZbe1faHBJv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a7PCWmBXGcXJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "## type of model and module to use\n",
        "class TextClassifier(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "                    #size, dimentions, hidden layer, output layer\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    #first the embedding  from the library, our size and the dimention\n",
        "\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "    #recurrent neural network, emedding, hidden layer, num of layers, processing batcher one by one\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    #forward conecction to lineal layer having the hidden and output\n",
        "\n",
        "  def fordwar(self, text):\n",
        "    #always forwdard class, in this case recieving text\n",
        "\n",
        "    embedded = self.embedding(text)\n",
        "    #generating embedding\n",
        "\n",
        "    output, (hidden, cell) = self.rnn(embedded)\n",
        "    #conexion between hidden and embeed\n",
        "\n",
        "    final_hidden = hidden[-1]\n",
        "    #getting the final versión of hidden layer\n",
        "\n",
        "    return self.fc(final_hidden)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reviewing code Step by step\n",
        "\n",
        "\n",
        "\n",
        "1.   Definned a class called TextClassifier taking data from nn.Module\n",
        "2.   Build the layers in our model: one layer to embedding, one layer to LSTM using 2 layers and hidden_dim hidden layers for each layer, finally a lineal layer as output\n",
        "3.  Using the method forward we created an embedding with inpout text using the embedding layer\n",
        "4.   Then through LSTM layer using the embedding we get the final hidden layer\n",
        "5.   Finally, using the final hidden layer through the lineal layer we get the output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uIbtUR5cj-Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to use the model you need to instance it like this:"
      ],
      "metadata": {
        "id": "2i3Z0_-ImdqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000 # its an hyperparameter, it could be even 60,000\n",
        "embedding_dim = 100 # even 700\n",
        "hidden_dim = 256 #as conventional use\n",
        "output_dim = 2 # because it´s a classification model\n",
        "\n",
        "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, output_dim )"
      ],
      "metadata": {
        "id": "5UGgqdX3JG4N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see the structure of our model"
      ],
      "metadata": {
        "id": "oh3JzHKbn6Dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJLLDO_En4Gl",
        "outputId": "1cc28160-c2fb-499b-dcb7-4b35feeef18f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): Embedding(1000, 100)\n",
              "  (rnn): LSTM(100, 256, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples creating tensors with Pytorch"
      ],
      "metadata": {
        "id": "GCBPUz8X00KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9fqNmeplYMt",
        "outputId": "200ed0ce-7342-4830-fecd-4be65df2b798"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "escalar = torch.randn(1)\n",
        "vector = torch.zeros(1,10)\n",
        "matrix = torch.ones(2,2)\n",
        "\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJh_0EFX0vG6",
        "outputId": "1d04404b-33c7-43d2-bf73-a5ad67518440"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also we´re able to build structures without common name"
      ],
      "metadata": {
        "id": "EJT7kgRw9TPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = torch.randn(5,2,3)\n",
        "\n",
        "t5\n",
        "#the dimentions could be calculated only counting the number of \"[\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaiSVZvc9GrB",
        "outputId": "f3fb4451-4e60-4625-8af1-9a45786ebfd6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6896, -0.5629, -0.3620],\n",
              "         [ 0.2421, -1.7086,  1.2837]],\n",
              "\n",
              "        [[-0.0082,  1.4978, -1.1570],\n",
              "         [ 0.7207,  1.3596, -0.7923]],\n",
              "\n",
              "        [[ 0.4302,  0.9412, -0.0191],\n",
              "         [-0.2332, -0.5620,  1.5919]],\n",
              "\n",
              "        [[ 0.2214, -0.6535,  1.3733],\n",
              "         [-1.3950,  0.6673, -0.3822]],\n",
              "\n",
              "        [[-2.2183, -1.2212,  2.5671],\n",
              "         [-1.0010,  0.2087,  0.8716]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also the tensors are able to store the values that we decide"
      ],
      "metadata": {
        "id": "wmbQxbZC-f7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[2,2], [3,3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y2_-suc-R6Y",
        "outputId": "f60524f0-cd27-4801-ae9b-cdddcae383f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2],\n",
              "        [3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debugging operations using tensors\n",
        "\n",
        "There are 3 most common issues working with tensors, being the following reasons:\n",
        "\n",
        "1. Shape or size.\n",
        "2. The datatype\n",
        "3. The device where the tensor is located"
      ],
      "metadata": {
        "id": "7SMlr33Z_xh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`shape` tell us how are organizated the elements inside the tensor"
      ],
      "metadata": {
        "id": "yq5Ho_OyAYvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The shape of the matrix is {matrix.shape}\")\n",
        "print(f\"The shape of f5 is {t5.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9CcghNY-oV4",
        "outputId": "677f3905-a95c-43c5-fd5a-fa895ccd4ecd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the matrix is torch.Size([2, 2])\n",
            "The shape of f5 is torch.Size([5, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also we are allowed to know the dimention"
      ],
      "metadata": {
        "id": "WL_9A-A2BMv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The shape of the matrix is {matrix.ndim}\")\n",
        "print(f\"The shape of the t5 is {t5.ndim}\")"
      ],
      "metadata": {
        "id": "0TFxTSaNA-YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab841ec3-31ab-4f5d-a6d5-9e18d39b5ad7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the matrix is 2\n",
            "The shape of the t5 is 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors could have differents types of elements, It´s very important to know which type are we using"
      ],
      "metadata": {
        "id": "5JNxffqrrVgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The tensor matrix has this type of elements: {matrix.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys4CZvFYrKE4",
        "outputId": "c7b04906-c177-47bb-a735-7ba8a6a3d2f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor matrix has this type of elements: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xxLbkl-Or3jx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}